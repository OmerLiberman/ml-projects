{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset - https://www.kaggle.com/c/dogs-vs-cats/data\n",
    "\n",
    "Source Code - https://machinelearningmastery.com/how-to-develop-a-convolutional-neural-network-to-classify-photos-of-dogs-and-cats/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data locations\n",
    "training_set_first_class = \"/data/dataset/training_set/dogs/\"\n",
    "training_set_second_class = \"/data/dataset/training_set/cats/\"\n",
    "\n",
    "test_set_first_class = \"/data/dataset/test_set/dogs/\"\n",
    "test_set_second_class = \"/data/dataset/test_set/cats/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images need to be standarized so they'll have the same size.\n",
    "Usually images are changes to small squares, here we are changing to 200*200 squares.\n",
    "Smaller inputs mean a model that is faster to train (the size of the inputs is the number of pixels in the image).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "import imghdr\n",
    "from numpy import asarray\n",
    "from numpy import save\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/data/dataset/training_set/dogs/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-453faa41c0d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Images loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtraining_set_first_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_set_second_class\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mimage_full_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/data/dataset/training_set/dogs/'"
     ]
    }
   ],
   "source": [
    "FIRST_CLASS_LABEL, SECOND_CLASS_LABEL = 0, 1\n",
    "\n",
    "IMG_SIZE = (200, 200)\n",
    "\n",
    "images_train, labels_train = [], []\n",
    "images_test, labels_test = [], []\n",
    "\n",
    "# Images loading\n",
    "for folder in [training_set_first_class, training_set_second_class]:\n",
    "    for file in listdir(folder):\n",
    "        if file.endswith(\".jpg\"):\n",
    "            image_full_path = folder + file\n",
    "\n",
    "            # Determine class\n",
    "            label = FIRST_CLASS_LABEL\n",
    "            if folder == training_set_second_class:\n",
    "                label = SECOND_CLASS_LABEL\n",
    "\n",
    "            # Image loading\n",
    "            image = load_img(image_full_path, target_size=IMG_SIZE)\n",
    "\n",
    "            # Convert image to numpy array\n",
    "            image = img_to_array(image)\n",
    "\n",
    "            # Store\n",
    "            images_train.append(image)\n",
    "            labels_train.append(label)\n",
    "\n",
    "for folder in [test_set_first_class, test_set_second_class]:\n",
    "    for file in listdir(folder):\n",
    "        if file.endswith(\".jpg\"):\n",
    "            image_full_path = folder + file\n",
    "\n",
    "            # Determine class\n",
    "            label = FIRST_CLASS_LABEL\n",
    "            if folder == test_set_second_class:\n",
    "                label = SECOND_CLASS_LABEL\n",
    "\n",
    "            # Image loading\n",
    "            image = load_img(image_full_path, target_size=IMG_SIZE)\n",
    "\n",
    "            # Convert image to numpy array\n",
    "            image = img_to_array(image)\n",
    "\n",
    "            # Store\n",
    "            images_test.append(image)\n",
    "            labels_test.append(label)\n",
    "\n",
    "# Convert to a munpy arrays\n",
    "images_train = asarray(images_train)\n",
    "images_train /= 255\n",
    "labels_train = asarray(labels_train)\n",
    "\n",
    "images_test = asarray(images_test)\n",
    "images_test /= 255\n",
    "labels_test = asarray(labels_test)\n",
    "\n",
    "# Saving the images and the labels\n",
    "save('X_train', images_train)\n",
    "save('y_train', labels_train)\n",
    "\n",
    "save('X_test', images_test)\n",
    "save('y_test', labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, its time to build the CNN.\n",
    "The architecture which is used here uses convolutions of 3*3\n",
    "followed by a max-pooling layer.\n",
    "Means that each layer is composed of:\n",
    "Conv2D + MaxPooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def init_model(img_width, img_height):\n",
    "    model = tf.keras.models.Sequential()\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(32, (3, 3), input_shape=(img_width, img_height, 3)))\n",
    "    model.add(tf.keras.layers.Activation('relu'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(32, (3, 3)))\n",
    "    model.add(tf.keras.layers.Activation('relu'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(64, (3, 3)))\n",
    "    model.add(tf.keras.layers.Activation('relu'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(64))\n",
    "    model.add(tf.keras.layers.Activation('relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "    model.add(tf.keras.layers.Activation('sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='rmsprop',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import load\n",
    "\n",
    "model = init_model(IMG_SIZE[0], IMG_SIZE[1])\n",
    "\n",
    "X_train = load('X_train.npy')\n",
    "y_train = load('y_train.npy')\n",
    "\n",
    "BATCH_SIZE=64\n",
    "EPOCHS=20\n",
    "\n",
    "model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE)\n",
    "\n",
    "# model.save('trained_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# evaluate model:\n",
    "# trained_model = load_model('trained_model.h5')\n",
    "\n",
    "X_test = load('X_test.npy')\n",
    "y_test = load('y_test.npy')\n",
    "\n",
    "loss, metric_val = trained_model.evaluate(x=X_test, y=y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
