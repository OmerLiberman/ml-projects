{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Speech Classification with Voila**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **About speech classification**\n",
    "\n",
    "Speech classification is a interdisciplinary subfield of computational linguistics that develops methodologies and technologies that enables the recognition and translation of spoken language into text by computers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **The model**\n",
    "\n",
    "The technique which we are going to use here is to convert each wav file to a spectrogram and then to apply image classification techniques. In this example, we are going to use convolutional neural network model with 3 layers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **The dataset**\n",
    "???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **How-to-use**\n",
    "\n",
    "1) **Trying the data**: the user can try listenting to samples (one from each class) of the dataset by picking a word and then press 'play', when the user pressed the play button - the audio is heard and an image describes the \"wave\" of the sound appears.\n",
    "\n",
    "2) **Predicting by recording** : in order to test the model, the user can record himself by clicking 'Record'. Then the record is saved and the user is able to listen to his own recording by clicking 'Play Record'.\n",
    "\n",
    "3) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"/data/speech_recog_smaller_ds\"\n",
    "path = \"/Users/omerliberman/Desktop/datasets/mnist_recordings_ds\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_classes = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Trying the dataset !**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random\n",
    "import soundfile as sf\n",
    "import sounddevice as sd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "from ipywidgets import Button, VBox, HBox, GridspecLayout, Layout, RadioButtons, Image, Text, FloatText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create samples from all classes.\n",
    "sub_folders = [f.path for f in os.scandir(path) if f.is_dir() and not f.path.endswith(\".cnvrg\")]\n",
    "\n",
    "random_files = []\n",
    "for sub_folder in sub_folders:\n",
    "    rand_file = random.choice([file for file in os.listdir(sub_folder) if file.endswith('.wav')])\n",
    "    label = sub_folder.split('/')[-1]\n",
    "    random_files.append((sub_folder + \"/\" + rand_file, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_single_spectrogram(path_to_wav, spectrogram_path):\n",
    "    samplingFrequency, signalData = wavfile.read(path_to_wav)\n",
    "    spectrogram = plt.plot(signalData)\n",
    "    plt.axis('off')\n",
    "    plt.savefig(spectrogram_path, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_sound_and_create_spectrogram(_=None):\n",
    "    path_of_wav_to_play = [aud for aud in random_files if aud[1] == trying_audio_wid.value][0][0]    \n",
    "    data, fs = sf.read(path_of_wav_to_play, dtype='float32')\n",
    "    sd.play(data, fs)\n",
    "    \n",
    "    spectrogram_img = get_single_spectrogram(path_of_wav_to_play, \"sample_spectrogram.png\")\n",
    "    file = open(\"sample_spectrogram.png\", \"rb\")\n",
    "    image = file.read()\n",
    "    spectrogram_wid.value = image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection word button.\n",
    "trying_audio_wid = RadioButtons(options=all_classes,\n",
    "                                value=all_classes[0],\n",
    "                                description='Word:',\n",
    "                                disabled=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Playing word button.\n",
    "play_button = Button(description='Play', layout={'width': '128px'})\n",
    "play_button.on_click(play_sound_and_create_spectrogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spectrogram image widget.\n",
    "file = open(\"white.png\", \"rb\")\n",
    "image = file.read()\n",
    "spectrogram_wid = Image(value=image,\n",
    "                        format='png',\n",
    "                        width=128,\n",
    "                        height=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping the play button and the spectrogram.\n",
    "vb_of_play_and_spectrogram = VBox([play_button, spectrogram_wid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "707d20bd730f41d28119f542bbbb01b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(RadioButtons(description='Word:', options=('0', '1', '2', '3', '4', '5', '6', '7', '8', '9'), v…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Grouping all the widgets.\n",
    "HBox([trying_audio_wid, vb_of_play_and_spectrogram])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Record yourself !**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "from scipy.io.wavfile import write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_user(_=None):\n",
    "    fs = 16000  # Sample rate\n",
    "    seconds = 1.2  # Duration of recording\n",
    "    status_wid.value = \"Recording...\"\n",
    "    myrecording = sd.rec(int(seconds * fs), samplerate=fs, channels=2)\n",
    "    sd.wait()\n",
    "    write('user_recording.wav', fs, myrecording)\n",
    "    status_wid.value = \"Recorded\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record user button.\n",
    "record_button = Button(description='Record')\n",
    "record_button.on_click(record_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_user_recording(_=None):\n",
    "    status_wid.value = \"Playing...\"\n",
    "    data, fs = sf.read('user_recording.wav', dtype='float32')\n",
    "    sd.play(data, fs)\n",
    "    \n",
    "    sleep(3)\n",
    "    status_wid.value = status_wid.placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play user's record button.\n",
    "play_recorded_button = Button(description='Play record')\n",
    "play_recorded_button.on_click(play_user_recording)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "hb = HBox([record_button, play_recorded_button])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text widget status.\n",
    "status_wid = Text(placeholder='Record yourself !', disabled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c300c2bbbd34e1f975cf857c7150db2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Button(description='Record', style=ButtonStyle()), Button(description='Play reco…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vb = VBox([hb, status_wid])\n",
    "\n",
    "vb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Use the model to predict your record**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'9': 0,\n",
       " '0': 1,\n",
       " '7': 2,\n",
       " '6': 3,\n",
       " '1': 4,\n",
       " '8': 5,\n",
       " '4': 6,\n",
       " '3': 7,\n",
       " '2': 8,\n",
       " '5': 9}"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = load_model('cnn_model.h5')\n",
    "\n",
    "dict_of_labels = None\n",
    "with open('labels_dictionary.json') as f:\n",
    "    dict_of_labels = json.load(f)\n",
    "    \n",
    "dict_of_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(_=None):\n",
    "    # Preparing the recorded file for prediction.\n",
    "    wav_file_to_predict = 'user_recording.wav'\n",
    "\n",
    "    get_single_spectrogram(wav_file_to_predict, 'img_to_predict.png')\n",
    "\n",
    "    image = load_img('img_to_predict.png', target_size=(128, 128), color_mode=\"grayscale\")\n",
    "\n",
    "    image = img_to_array(image)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    image /= 255.\n",
    "    \n",
    "    # Insert the results to their true places.\n",
    "    prediction_vec = model.predict(image)\n",
    "        \n",
    "    label_of_pred = np.argmax(prediction_vec)\n",
    "    pred_prob = prediction_vec[0][label_of_pred]\n",
    "    \n",
    "    literal_label = [item[0] for item in dict_of_labels.items() if item[1] == label_of_pred][0]\n",
    "    \n",
    "    prediction_wid.value = literal_label\n",
    "    prob_wid.value = pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_button = Button(description='Predict', layout={'width': '300px'})\n",
    "predict_button.on_click(make_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text widget which is going to include to prediction label.\n",
    "prediction_wid =  Text(description='Prediction: ', placeholder='Prediction', disabled=True)\n",
    "# text widget which is going to include to prediction probability.\n",
    "prob_wid =  FloatText(description='Probability: ', placeholder=0.0, disabled=True)\n",
    "\n",
    "vb_pred_and_prob = VBox([prediction_wid, prob_wid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b4c6f2d5f9e42f8bcd983a03fbacfb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Button(description='Predict', layout=Layout(width='300px'), style=ButtonStyle()), VBox(children…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected conv2d_input to have shape (128, 128, 3) but got array with shape (128, 128, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-231-26701334b4e0>\u001b[0m in \u001b[0;36mmake_prediction\u001b[0;34m(_)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Insert the results to their true places.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mprediction_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mlabel_of_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1058\u001b[0m     \u001b[0;31m# generate symbolic tensors).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m     x, _, _ = self._standardize_user_data(\n\u001b[0;32m-> 1060\u001b[0;31m         x, check_steps=True, steps_name='steps', steps=steps)\n\u001b[0m\u001b[1;32m   1061\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2649\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2651\u001b[0;31m           exception_prefix='input')\n\u001b[0m\u001b[1;32m   2652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2653\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    383\u001b[0m                              \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m                              \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m                              str(data_shape))\n\u001b[0m\u001b[1;32m    386\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected conv2d_input to have shape (128, 128, 3) but got array with shape (128, 128, 1)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "vb_prediction = VBox([predict_button, vb_pred_and_prob])\n",
    "\n",
    "vb_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
